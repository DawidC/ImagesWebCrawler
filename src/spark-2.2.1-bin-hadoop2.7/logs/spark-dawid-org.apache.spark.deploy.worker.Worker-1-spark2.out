Spark Command: /usr/lib/jvm/java-1.8.0-openjdk-amd64/bin/java -cp /home/dawid/spark/spark-2.2.1-bin-hadoop2.7//conf/:/home/dawid/spark/spark-2.2.1-bin-hadoop2.7/jars/* -Xmx1g org.apache.spark.deploy.worker.Worker --webui-port 8081 spark://192.168.56.101:7077
========================================
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
18/01/22 14:51:06 INFO Worker: Started daemon with process name: 1482@spark2
18/01/22 14:51:06 INFO SignalUtils: Registered signal handler for TERM
18/01/22 14:51:06 INFO SignalUtils: Registered signal handler for HUP
18/01/22 14:51:06 INFO SignalUtils: Registered signal handler for INT
18/01/22 14:51:06 WARN Utils: Your hostname, spark2 resolves to a loopback address: 127.0.1.1; using 192.168.56.102 instead (on interface enp0s3)
18/01/22 14:51:06 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address
18/01/22 14:51:07 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
18/01/22 14:51:07 INFO SecurityManager: Changing view acls to: dawid
18/01/22 14:51:07 INFO SecurityManager: Changing modify acls to: dawid
18/01/22 14:51:07 INFO SecurityManager: Changing view acls groups to: 
18/01/22 14:51:07 INFO SecurityManager: Changing modify acls groups to: 
18/01/22 14:51:07 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(dawid); groups with view permissions: Set(); users  with modify permissions: Set(dawid); groups with modify permissions: Set()
18/01/22 14:51:08 INFO Utils: Successfully started service 'sparkWorker' on port 34828.
18/01/22 14:51:08 INFO Worker: Starting Spark worker 192.168.56.102:34828 with 8 cores, 1024.0 MB RAM
18/01/22 14:51:08 INFO Worker: Running Spark version 2.2.1
18/01/22 14:51:08 INFO Worker: Spark home: /home/dawid/spark/spark-2.2.1-bin-hadoop2.7
18/01/22 14:51:09 INFO Utils: Successfully started service 'WorkerUI' on port 8081.
18/01/22 14:51:10 INFO WorkerWebUI: Bound WorkerWebUI to 0.0.0.0, and started at http://192.168.56.102:8081
18/01/22 14:51:10 INFO Worker: Connecting to master 192.168.56.101:7077...
18/01/22 14:51:10 INFO TransportClientFactory: Successfully created connection to /192.168.56.101:7077 after 137 ms (0 ms spent in bootstraps)
18/01/22 14:51:10 INFO Worker: Successfully registered with master spark://192.168.56.101:7077
18/01/22 14:52:30 INFO Worker: Asked to launch executor app-20180122113453-0000/0 for testTF.py
18/01/22 14:52:30 INFO SecurityManager: Changing view acls to: dawid
18/01/22 14:52:30 INFO SecurityManager: Changing modify acls to: dawid
18/01/22 14:52:30 INFO SecurityManager: Changing view acls groups to: 
18/01/22 14:52:30 INFO SecurityManager: Changing modify acls groups to: 
18/01/22 14:52:30 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(dawid); groups with view permissions: Set(); users  with modify permissions: Set(dawid); groups with modify permissions: Set()
18/01/22 14:52:30 INFO ExecutorRunner: Launch command: "/usr/lib/jvm/java-1.8.0-openjdk-amd64/bin/java" "-cp" "/home/dawid/spark/spark-2.2.1-bin-hadoop2.7//conf/:/home/dawid/spark/spark-2.2.1-bin-hadoop2.7/jars/*" "-Xmx1024M" "-Dspark.driver.port=41779" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@192.168.56.102:41779" "--executor-id" "0" "--hostname" "192.168.56.102" "--cores" "8" "--app-id" "app-20180122113453-0000" "--worker-url" "spark://Worker@192.168.56.102:34828"
18/01/22 14:53:47 INFO Worker: Asked to kill executor app-20180122113453-0000/0
18/01/22 14:53:47 INFO ExecutorRunner: Runner thread for executor app-20180122113453-0000/0 interrupted
18/01/22 14:53:47 INFO ExecutorRunner: Killing process!
18/01/22 14:53:47 INFO Worker: Executor app-20180122113453-0000/0 finished with state KILLED exitStatus 143
18/01/22 14:53:47 INFO ExternalShuffleBlockResolver: Application app-20180122113453-0000 removed, cleanupLocalDirs = true
18/01/22 14:53:47 INFO Worker: Cleaning up local directories for application app-20180122113453-0000
18/01/22 14:54:33 INFO Worker: Asked to launch executor app-20180122113657-0001/0 for testTF.py
18/01/22 14:54:33 INFO SecurityManager: Changing view acls to: dawid
18/01/22 14:54:33 INFO SecurityManager: Changing modify acls to: dawid
18/01/22 14:54:33 INFO SecurityManager: Changing view acls groups to: 
18/01/22 14:54:33 INFO SecurityManager: Changing modify acls groups to: 
18/01/22 14:54:33 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(dawid); groups with view permissions: Set(); users  with modify permissions: Set(dawid); groups with modify permissions: Set()
18/01/22 14:54:33 INFO ExecutorRunner: Launch command: "/usr/lib/jvm/java-1.8.0-openjdk-amd64/bin/java" "-cp" "/home/dawid/spark/spark-2.2.1-bin-hadoop2.7//conf/:/home/dawid/spark/spark-2.2.1-bin-hadoop2.7/jars/*" "-Xmx1024M" "-Dspark.driver.port=45597" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@192.168.56.102:45597" "--executor-id" "0" "--hostname" "192.168.56.102" "--cores" "8" "--app-id" "app-20180122113657-0001" "--worker-url" "spark://Worker@192.168.56.102:34828"
18/01/22 14:54:35 INFO Worker: Asked to kill executor app-20180122113657-0001/0
18/01/22 14:54:35 INFO ExecutorRunner: Runner thread for executor app-20180122113657-0001/0 interrupted
18/01/22 14:54:35 INFO ExecutorRunner: Killing process!
18/01/22 14:54:35 INFO Worker: Executor app-20180122113657-0001/0 finished with state KILLED exitStatus 143
18/01/22 14:54:35 INFO ExternalShuffleBlockResolver: Application app-20180122113657-0001 removed, cleanupLocalDirs = true
18/01/22 14:54:35 INFO Worker: Cleaning up local directories for application app-20180122113657-0001
18/01/22 14:56:23 INFO Worker: Asked to launch executor app-20180122113846-0002/0 for testTF.py
18/01/22 14:56:23 INFO SecurityManager: Changing view acls to: dawid
18/01/22 14:56:23 INFO SecurityManager: Changing modify acls to: dawid
18/01/22 14:56:23 INFO SecurityManager: Changing view acls groups to: 
18/01/22 14:56:23 INFO SecurityManager: Changing modify acls groups to: 
18/01/22 14:56:23 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(dawid); groups with view permissions: Set(); users  with modify permissions: Set(dawid); groups with modify permissions: Set()
18/01/22 14:56:23 INFO ExecutorRunner: Launch command: "/usr/lib/jvm/java-1.8.0-openjdk-amd64/bin/java" "-cp" "/home/dawid/spark/spark-2.2.1-bin-hadoop2.7//conf/:/home/dawid/spark/spark-2.2.1-bin-hadoop2.7/jars/*" "-Xmx1024M" "-Dspark.driver.port=41364" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@192.168.56.102:41364" "--executor-id" "0" "--hostname" "192.168.56.102" "--cores" "8" "--app-id" "app-20180122113846-0002" "--worker-url" "spark://Worker@192.168.56.102:34828"
18/01/22 15:04:20 INFO Worker: Asked to kill executor app-20180122113846-0002/0
18/01/22 15:04:20 INFO ExecutorRunner: Runner thread for executor app-20180122113846-0002/0 interrupted
18/01/22 15:04:20 INFO ExecutorRunner: Killing process!
18/01/22 15:04:31 INFO Worker: Executor app-20180122113846-0002/0 finished with state KILLED exitStatus 137
18/01/22 15:04:31 INFO Worker: Cleaning up local directories for application app-20180122113846-0002
18/01/22 15:04:31 INFO ExternalShuffleBlockResolver: Application app-20180122113846-0002 removed, cleanupLocalDirs = true

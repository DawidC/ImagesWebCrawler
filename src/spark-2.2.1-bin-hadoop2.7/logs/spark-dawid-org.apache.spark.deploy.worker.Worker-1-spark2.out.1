Spark Command: /usr/lib/jvm/java-1.8.0-openjdk-amd64/bin/java -cp /home/dawid/spark/spark-2.2.1-bin-hadoop2.7//conf/:/home/dawid/spark/spark-2.2.1-bin-hadoop2.7/jars/* -Xmx1g org.apache.spark.deploy.worker.Worker --webui-port 8081 spark://192.168.56.101
========================================
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
18/01/22 14:50:51 INFO Worker: Started daemon with process name: 1421@spark2
18/01/22 14:50:51 INFO SignalUtils: Registered signal handler for TERM
18/01/22 14:50:51 INFO SignalUtils: Registered signal handler for HUP
18/01/22 14:50:51 INFO SignalUtils: Registered signal handler for INT
18/01/22 14:50:51 WARN Utils: Your hostname, spark2 resolves to a loopback address: 127.0.1.1; using 192.168.56.102 instead (on interface enp0s3)
18/01/22 14:50:51 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address
18/01/22 14:50:54 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
18/01/22 14:50:54 INFO SecurityManager: Changing view acls to: dawid
18/01/22 14:50:54 INFO SecurityManager: Changing modify acls to: dawid
18/01/22 14:50:54 INFO SecurityManager: Changing view acls groups to: 
18/01/22 14:50:54 INFO SecurityManager: Changing modify acls groups to: 
18/01/22 14:50:54 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(dawid); groups with view permissions: Set(); users  with modify permissions: Set(dawid); groups with modify permissions: Set()
18/01/22 14:50:56 INFO Utils: Successfully started service 'sparkWorker' on port 35846.
Exception in thread "main" org.apache.spark.SparkException: Invalid master URL: spark://192.168.56.101
	at org.apache.spark.util.Utils$.extractHostPortFromSparkUrl(Utils.scala:2409)
	at org.apache.spark.rpc.RpcAddress$.fromSparkURL(RpcAddress.scala:47)
	at org.apache.spark.deploy.worker.Worker$$anonfun$14.apply(Worker.scala:763)
	at org.apache.spark.deploy.worker.Worker$$anonfun$14.apply(Worker.scala:763)
	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234)
	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)
	at scala.collection.TraversableLike$class.map(TraversableLike.scala:234)
	at scala.collection.mutable.ArrayOps$ofRef.map(ArrayOps.scala:186)
	at org.apache.spark.deploy.worker.Worker$.startRpcEnvAndEndpoint(Worker.scala:763)
	at org.apache.spark.deploy.worker.Worker$.main(Worker.scala:743)
	at org.apache.spark.deploy.worker.Worker.main(Worker.scala)

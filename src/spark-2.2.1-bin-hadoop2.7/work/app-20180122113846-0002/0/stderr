Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
18/01/22 14:56:25 INFO CoarseGrainedExecutorBackend: Started daemon with process name: 1878@spark2
18/01/22 14:56:25 INFO SignalUtils: Registered signal handler for TERM
18/01/22 14:56:25 INFO SignalUtils: Registered signal handler for HUP
18/01/22 14:56:25 INFO SignalUtils: Registered signal handler for INT
18/01/22 14:56:25 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
18/01/22 14:56:26 WARN Utils: Your hostname, spark2 resolves to a loopback address: 127.0.1.1; using 192.168.56.102 instead (on interface enp0s3)
18/01/22 14:56:26 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address
18/01/22 14:56:26 INFO SecurityManager: Changing view acls to: dawid
18/01/22 14:56:26 INFO SecurityManager: Changing modify acls to: dawid
18/01/22 14:56:26 INFO SecurityManager: Changing view acls groups to: 
18/01/22 14:56:26 INFO SecurityManager: Changing modify acls groups to: 
18/01/22 14:56:26 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(dawid); groups with view permissions: Set(); users  with modify permissions: Set(dawid); groups with modify permissions: Set()
18/01/22 14:56:26 INFO TransportClientFactory: Successfully created connection to /192.168.56.102:41364 after 113 ms (0 ms spent in bootstraps)
18/01/22 14:56:27 INFO SecurityManager: Changing view acls to: dawid
18/01/22 14:56:27 INFO SecurityManager: Changing modify acls to: dawid
18/01/22 14:56:27 INFO SecurityManager: Changing view acls groups to: 
18/01/22 14:56:27 INFO SecurityManager: Changing modify acls groups to: 
18/01/22 14:56:27 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(dawid); groups with view permissions: Set(); users  with modify permissions: Set(dawid); groups with modify permissions: Set()
18/01/22 14:56:27 INFO TransportClientFactory: Successfully created connection to /192.168.56.102:41364 after 4 ms (0 ms spent in bootstraps)
18/01/22 14:56:27 INFO DiskBlockManager: Created local directory at /tmp/spark-ab46eec0-9b20-4dc3-8421-c41dbe65512c/executor-163093a3-f502-4acc-be56-2126fec8d702/blockmgr-941ed61c-30bc-4643-bb0c-1d7b8eba1d2c
18/01/22 14:56:27 INFO MemoryStore: MemoryStore started with capacity 413.9 MB
18/01/22 14:56:27 INFO CoarseGrainedExecutorBackend: Connecting to driver: spark://CoarseGrainedScheduler@192.168.56.102:41364
18/01/22 14:56:27 INFO WorkerWatcher: Connecting to worker spark://Worker@192.168.56.102:34828
18/01/22 14:56:27 INFO TransportClientFactory: Successfully created connection to /192.168.56.102:34828 after 14 ms (0 ms spent in bootstraps)
18/01/22 14:56:27 INFO WorkerWatcher: Successfully connected to spark://Worker@192.168.56.102:34828
18/01/22 14:56:28 INFO CoarseGrainedExecutorBackend: Successfully registered with driver
18/01/22 14:56:28 INFO Executor: Starting executor ID 0 on host 192.168.56.102
18/01/22 14:56:28 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 40081.
18/01/22 14:56:28 INFO NettyBlockTransferService: Server created on 192.168.56.102:40081
18/01/22 14:56:28 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
18/01/22 14:56:28 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(0, 192.168.56.102, 40081, None)
18/01/22 14:56:28 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(0, 192.168.56.102, 40081, None)
18/01/22 14:56:28 INFO BlockManager: Initialized BlockManager: BlockManagerId(0, 192.168.56.102, 40081, None)
18/01/22 14:57:16 INFO CoarseGrainedExecutorBackend: Got assigned task 0
18/01/22 14:57:16 INFO CoarseGrainedExecutorBackend: Got assigned task 1
18/01/22 14:57:16 INFO CoarseGrainedExecutorBackend: Got assigned task 2
18/01/22 14:57:16 INFO CoarseGrainedExecutorBackend: Got assigned task 3
18/01/22 14:57:16 INFO CoarseGrainedExecutorBackend: Got assigned task 4
18/01/22 14:57:16 INFO CoarseGrainedExecutorBackend: Got assigned task 5
18/01/22 14:57:16 INFO CoarseGrainedExecutorBackend: Got assigned task 6
18/01/22 14:57:16 INFO CoarseGrainedExecutorBackend: Got assigned task 7
18/01/22 14:57:16 INFO Executor: Running task 2.0 in stage 0.0 (TID 2)
18/01/22 14:57:16 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
18/01/22 14:57:16 INFO Executor: Running task 5.0 in stage 0.0 (TID 5)
18/01/22 14:57:16 INFO Executor: Running task 6.0 in stage 0.0 (TID 6)
18/01/22 14:57:16 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
18/01/22 14:57:16 INFO Executor: Running task 4.0 in stage 0.0 (TID 4)
18/01/22 14:57:16 INFO Executor: Running task 3.0 in stage 0.0 (TID 3)
18/01/22 14:57:16 INFO Executor: Running task 7.0 in stage 0.0 (TID 7)
18/01/22 14:57:16 INFO Executor: Fetching spark://192.168.56.102:41364/files/testTF.py with timestamp 1516629382696
18/01/22 14:57:16 INFO TransportClientFactory: Successfully created connection to /192.168.56.102:41364 after 15 ms (0 ms spent in bootstraps)
18/01/22 14:57:16 INFO Utils: Fetching spark://192.168.56.102:41364/files/testTF.py to /tmp/spark-ab46eec0-9b20-4dc3-8421-c41dbe65512c/executor-163093a3-f502-4acc-be56-2126fec8d702/spark-c2b99edc-0670-49e5-97ea-47e7b8c0708a/fetchFileTemp4229901747364947083.tmp
18/01/22 14:57:16 INFO Utils: Copying /tmp/spark-ab46eec0-9b20-4dc3-8421-c41dbe65512c/executor-163093a3-f502-4acc-be56-2126fec8d702/spark-c2b99edc-0670-49e5-97ea-47e7b8c0708a/-2022604401516629382696_cache to /home/dawid/spark/spark-2.2.1-bin-hadoop2.7/work/app-20180122113846-0002/0/./testTF.py
18/01/22 14:57:16 INFO TorrentBroadcast: Started reading broadcast variable 2
18/01/22 14:57:16 INFO TransportClientFactory: Successfully created connection to /192.168.56.102:40756 after 3 ms (0 ms spent in bootstraps)
18/01/22 14:57:16 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 4.6 KB, free 413.9 MB)
18/01/22 14:57:16 INFO TorrentBroadcast: Reading broadcast variable 2 took 179 ms
18/01/22 14:57:16 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 6.7 KB, free 413.9 MB)
18/01/22 14:57:19 INFO TorrentBroadcast: Started reading broadcast variable 0
18/01/22 14:57:19 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 23.2 KB, free 413.9 MB)
18/01/22 14:57:19 INFO TorrentBroadcast: Reading broadcast variable 0 took 59 ms
18/01/22 14:57:19 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 416.0 B, free 413.9 MB)
18/01/22 14:57:19 INFO TorrentBroadcast: Started reading broadcast variable 1
18/01/22 14:57:19 INFO MemoryStore: Block broadcast_1_piece7 stored as bytes in memory (estimated size 4.0 MB, free 409.9 MB)
18/01/22 14:57:19 INFO MemoryStore: Block broadcast_1_piece23 stored as bytes in memory (estimated size 4.0 MB, free 405.9 MB)
18/01/22 14:57:19 INFO MemoryStore: Block broadcast_1_piece26 stored as bytes in memory (estimated size 4.0 MB, free 401.9 MB)
18/01/22 14:57:19 INFO MemoryStore: Block broadcast_1_piece4 stored as bytes in memory (estimated size 4.0 MB, free 397.9 MB)
18/01/22 14:57:19 INFO MemoryStore: Block broadcast_1_piece18 stored as bytes in memory (estimated size 4.0 MB, free 393.9 MB)
18/01/22 14:57:19 INFO MemoryStore: Block broadcast_1_piece1 stored as bytes in memory (estimated size 4.0 MB, free 389.9 MB)
18/01/22 14:57:19 INFO MemoryStore: Block broadcast_1_piece21 stored as bytes in memory (estimated size 4.0 MB, free 385.9 MB)
18/01/22 14:57:19 INFO MemoryStore: Block broadcast_1_piece8 stored as bytes in memory (estimated size 4.0 MB, free 381.9 MB)
18/01/22 14:57:20 INFO MemoryStore: Block broadcast_1_piece12 stored as bytes in memory (estimated size 4.0 MB, free 377.9 MB)
18/01/22 14:57:20 INFO MemoryStore: Block broadcast_1_piece27 stored as bytes in memory (estimated size 4.0 MB, free 373.9 MB)
18/01/22 14:57:20 INFO MemoryStore: Block broadcast_1_piece13 stored as bytes in memory (estimated size 4.0 MB, free 369.9 MB)
18/01/22 14:57:20 INFO MemoryStore: Block broadcast_1_piece11 stored as bytes in memory (estimated size 4.0 MB, free 365.9 MB)
18/01/22 14:57:20 INFO MemoryStore: Block broadcast_1_piece20 stored as bytes in memory (estimated size 4.0 MB, free 361.9 MB)
18/01/22 14:57:20 INFO MemoryStore: Block broadcast_1_piece16 stored as bytes in memory (estimated size 4.0 MB, free 357.9 MB)
18/01/22 14:57:20 INFO MemoryStore: Block broadcast_1_piece9 stored as bytes in memory (estimated size 4.0 MB, free 353.9 MB)
18/01/22 14:57:20 INFO MemoryStore: Block broadcast_1_piece6 stored as bytes in memory (estimated size 4.0 MB, free 349.9 MB)
18/01/22 14:57:20 INFO MemoryStore: Block broadcast_1_piece33 stored as bytes in memory (estimated size 642.2 KB, free 349.3 MB)
18/01/22 14:57:20 INFO MemoryStore: Block broadcast_1_piece5 stored as bytes in memory (estimated size 4.0 MB, free 345.3 MB)
18/01/22 14:57:20 INFO MemoryStore: Block broadcast_1_piece10 stored as bytes in memory (estimated size 4.0 MB, free 341.3 MB)
18/01/22 14:57:20 INFO MemoryStore: Block broadcast_1_piece29 stored as bytes in memory (estimated size 4.0 MB, free 337.3 MB)
18/01/22 14:57:20 INFO MemoryStore: Block broadcast_1_piece30 stored as bytes in memory (estimated size 4.0 MB, free 333.3 MB)
18/01/22 14:57:20 INFO MemoryStore: Block broadcast_1_piece22 stored as bytes in memory (estimated size 4.0 MB, free 329.3 MB)
18/01/22 14:57:20 INFO MemoryStore: Block broadcast_1_piece25 stored as bytes in memory (estimated size 4.0 MB, free 325.3 MB)
18/01/22 14:57:20 INFO MemoryStore: Block broadcast_1_piece32 stored as bytes in memory (estimated size 4.0 MB, free 321.3 MB)
18/01/22 14:57:20 INFO MemoryStore: Block broadcast_1_piece2 stored as bytes in memory (estimated size 4.0 MB, free 317.3 MB)
18/01/22 14:57:20 INFO MemoryStore: Block broadcast_1_piece24 stored as bytes in memory (estimated size 4.0 MB, free 313.3 MB)
18/01/22 14:57:20 INFO MemoryStore: Block broadcast_1_piece19 stored as bytes in memory (estimated size 4.0 MB, free 309.3 MB)
18/01/22 14:57:20 INFO MemoryStore: Block broadcast_1_piece15 stored as bytes in memory (estimated size 4.0 MB, free 305.3 MB)
18/01/22 14:57:20 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 4.0 MB, free 301.3 MB)
18/01/22 14:57:20 INFO MemoryStore: Block broadcast_1_piece31 stored as bytes in memory (estimated size 4.0 MB, free 297.3 MB)
18/01/22 14:57:21 INFO MemoryStore: Block broadcast_1_piece28 stored as bytes in memory (estimated size 4.0 MB, free 293.3 MB)
18/01/22 14:57:21 INFO MemoryStore: Block broadcast_1_piece14 stored as bytes in memory (estimated size 4.0 MB, free 289.3 MB)
18/01/22 14:57:21 INFO MemoryStore: Block broadcast_1_piece3 stored as bytes in memory (estimated size 4.0 MB, free 285.3 MB)
18/01/22 14:57:21 INFO MemoryStore: Block broadcast_1_piece17 stored as bytes in memory (estimated size 4.0 MB, free 281.3 MB)
18/01/22 14:57:21 INFO TorrentBroadcast: Reading broadcast variable 1 took 1545 ms
18/01/22 14:57:22 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 424.0 B, free 281.3 MB)
18/01/22 14:57:31 INFO PythonRunner: Times: total = 14198, boot = 1675, init = 12523, finish = 0
18/01/22 14:57:34 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 3683 bytes result sent to driver
18/01/22 14:58:49 WARN NettyRpcEnv: Ignored failure: java.util.concurrent.TimeoutException: Cannot receive any reply from 192.168.56.102:41364 in 10 seconds
18/01/22 14:58:51 WARN Executor: Issue communicating with driver in heartbeater
org.apache.spark.rpc.RpcTimeoutException: Futures timed out after [10 seconds]. This timeout is controlled by spark.executor.heartbeatInterval
	at org.apache.spark.rpc.RpcTimeout.org$apache$spark$rpc$RpcTimeout$$createRpcTimeoutException(RpcTimeout.scala:47)
	at org.apache.spark.rpc.RpcTimeout$$anonfun$addMessageIfTimeout$1.applyOrElse(RpcTimeout.scala:62)
	at org.apache.spark.rpc.RpcTimeout$$anonfun$addMessageIfTimeout$1.applyOrElse(RpcTimeout.scala:58)
	at scala.runtime.AbstractPartialFunction.apply(AbstractPartialFunction.scala:36)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:76)
	at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:92)
	at org.apache.spark.executor.Executor.org$apache$spark$executor$Executor$$reportHeartBeat(Executor.scala:738)
	at org.apache.spark.executor.Executor$$anon$2$$anonfun$run$1.apply$mcV$sp(Executor.scala:767)
	at org.apache.spark.executor.Executor$$anon$2$$anonfun$run$1.apply(Executor.scala:767)
	at org.apache.spark.executor.Executor$$anon$2$$anonfun$run$1.apply(Executor.scala:767)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1948)
	at org.apache.spark.executor.Executor$$anon$2.run(Executor.scala:767)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.util.concurrent.TimeoutException: Futures timed out after [10 seconds]
	at scala.concurrent.impl.Promise$DefaultPromise.ready(Promise.scala:219)
	at scala.concurrent.impl.Promise$DefaultPromise.result(Promise.scala:223)
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:201)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
	... 14 more
2018-01-22 14:59:45.491890: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX
2018-01-22 14:59:45.457213: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX
2018-01-22 14:59:45.537127: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX
2018-01-22 14:59:45.642540: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX
2018-01-22 14:59:46.101084: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX
2018-01-22 14:59:48.299442: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX
2018-01-22 14:59:52.140930: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX
18/01/22 15:00:47 WARN Executor: Issue communicating with driver in heartbeater
org.apache.spark.rpc.RpcTimeoutException: Futures timed out after [10 seconds]. This timeout is controlled by spark.executor.heartbeatInterval
	at org.apache.spark.rpc.RpcTimeout.org$apache$spark$rpc$RpcTimeout$$createRpcTimeoutException(RpcTimeout.scala:47)
	at org.apache.spark.rpc.RpcTimeout$$anonfun$addMessageIfTimeout$1.applyOrElse(RpcTimeout.scala:62)
	at org.apache.spark.rpc.RpcTimeout$$anonfun$addMessageIfTimeout$1.applyOrElse(RpcTimeout.scala:58)
	at scala.runtime.AbstractPartialFunction.apply(AbstractPartialFunction.scala:36)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:76)
	at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:92)
	at org.apache.spark.executor.Executor.org$apache$spark$executor$Executor$$reportHeartBeat(Executor.scala:738)
	at org.apache.spark.executor.Executor$$anon$2$$anonfun$run$1.apply$mcV$sp(Executor.scala:767)
	at org.apache.spark.executor.Executor$$anon$2$$anonfun$run$1.apply(Executor.scala:767)
	at org.apache.spark.executor.Executor$$anon$2$$anonfun$run$1.apply(Executor.scala:767)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1948)
	at org.apache.spark.executor.Executor$$anon$2.run(Executor.scala:767)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.util.concurrent.TimeoutException: Futures timed out after [10 seconds]
	at scala.concurrent.impl.Promise$DefaultPromise.ready(Promise.scala:219)
	at scala.concurrent.impl.Promise$DefaultPromise.result(Promise.scala:223)
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:201)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
	... 14 more
2018-01-22 15:00:52.819382: W tensorflow/core/framework/op_def_util.cc:334] Op BatchNormWithGlobalNormalization is deprecated. It will cease to work in GraphDef version 9. Use tf.nn.batch_normalization().
18/01/22 15:00:58 INFO PythonRunner: Times: total = 214995, boot = 2275, init = 11919, finish = 200801
18/01/22 15:01:00 WARN Executor: Issue communicating with driver in heartbeater
org.apache.spark.rpc.RpcTimeoutException: Cannot receive any reply from 192.168.56.102:41364 in 10 seconds. This timeout is controlled by spark.executor.heartbeatInterval
	at org.apache.spark.rpc.RpcTimeout.org$apache$spark$rpc$RpcTimeout$$createRpcTimeoutException(RpcTimeout.scala:47)
	at org.apache.spark.rpc.RpcTimeout$$anonfun$addMessageIfTimeout$1.applyOrElse(RpcTimeout.scala:62)
	at org.apache.spark.rpc.RpcTimeout$$anonfun$addMessageIfTimeout$1.applyOrElse(RpcTimeout.scala:58)
	at scala.runtime.AbstractPartialFunction.apply(AbstractPartialFunction.scala:36)
	at scala.util.Failure$$anonfun$recover$1.apply(Try.scala:216)
	at scala.util.Try$.apply(Try.scala:192)
	at scala.util.Failure.recover(Try.scala:216)
	at scala.concurrent.Future$$anonfun$recover$1.apply(Future.scala:326)
	at scala.concurrent.Future$$anonfun$recover$1.apply(Future.scala:326)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:32)
	at org.spark_project.guava.util.concurrent.MoreExecutors$SameThreadExecutorService.execute(MoreExecutors.java:293)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$1.execute(ExecutionContextImpl.scala:136)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:40)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:248)
	at scala.concurrent.Promise$class.complete(Promise.scala:55)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:153)
	at scala.concurrent.Future$$anonfun$map$1.apply(Future.scala:237)
	at scala.concurrent.Future$$anonfun$map$1.apply(Future.scala:237)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:32)
	at scala.concurrent.BatchingExecutor$Batch$$anonfun$run$1.processBatch$1(BatchingExecutor.scala:63)
	at scala.concurrent.BatchingExecutor$Batch$$anonfun$run$1.apply$mcV$sp(BatchingExecutor.scala:78)
	at scala.concurrent.BatchingExecutor$Batch$$anonfun$run$1.apply(BatchingExecutor.scala:55)
	at scala.concurrent.BatchingExecutor$Batch$$anonfun$run$1.apply(BatchingExecutor.scala:55)
	at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:72)
	at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:54)
	at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:601)
	at scala.concurrent.BatchingExecutor$class.execute(BatchingExecutor.scala:106)
	at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:599)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:40)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:248)
	at scala.concurrent.Promise$class.tryFailure(Promise.scala:112)
	at scala.concurrent.impl.Promise$DefaultPromise.tryFailure(Promise.scala:153)
	at org.apache.spark.rpc.netty.NettyRpcEnv.org$apache$spark$rpc$netty$NettyRpcEnv$$onFailure$1(NettyRpcEnv.scala:205)
	at org.apache.spark.rpc.netty.NettyRpcEnv$$anon$1.run(NettyRpcEnv.scala:242)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.util.concurrent.TimeoutException: Cannot receive any reply from 192.168.56.102:41364 in 10 seconds
	... 8 more
2018-01-22 15:01:12.597409: W tensorflow/core/framework/op_def_util.cc:334] Op BatchNormWithGlobalNormalization is deprecated. It will cease to work in GraphDef version 9. Use tf.nn.batch_normalization().
18/01/22 15:01:12 WARN NettyRpcEnv: Ignored message: HeartbeatResponse(false)
18/01/22 15:01:14 WARN TransportResponseHandler: Ignoring response for RPC 5151820379107031382 from /192.168.56.102:41364 (81 bytes) since it is not outstanding
2018-01-22 15:01:18.336933: W tensorflow/core/framework/op_def_util.cc:334] Op BatchNormWithGlobalNormalization is deprecated. It will cease to work in GraphDef version 9. Use tf.nn.batch_normalization().
18/01/22 15:01:19 INFO Executor: Finished task 4.0 in stage 0.0 (TID 4). 1811 bytes result sent to driver
18/01/22 15:01:26 INFO PythonRunner: Times: total = 247061, boot = 2281, init = 11893, finish = 232887
18/01/22 15:01:27 INFO Executor: Finished task 3.0 in stage 0.0 (TID 3). 2337 bytes result sent to driver
2018-01-22 15:01:28.746999: W tensorflow/core/framework/op_def_util.cc:334] Op BatchNormWithGlobalNormalization is deprecated. It will cease to work in GraphDef version 9. Use tf.nn.batch_normalization().
18/01/22 15:01:29 INFO PythonRunner: Times: total = 249747, boot = 2291, init = 11892, finish = 235564
18/01/22 15:01:29 INFO Executor: Finished task 2.0 in stage 0.0 (TID 2). 3026 bytes result sent to driver
18/01/22 15:01:33 INFO PythonRunner: Times: total = 255476, boot = 2265, init = 11936, finish = 241275
18/01/22 15:01:33 INFO Executor: Finished task 5.0 in stage 0.0 (TID 5). 2236 bytes result sent to driver
18/01/22 15:01:38 INFO PythonRunner: Times: total = 259949, boot = 2287, init = 11931, finish = 245731
18/01/22 15:01:39 INFO Executor: Finished task 7.0 in stage 0.0 (TID 7). 1755 bytes result sent to driver
2018-01-22 15:01:46.280237: W tensorflow/core/framework/op_def_util.cc:334] Op BatchNormWithGlobalNormalization is deprecated. It will cease to work in GraphDef version 9. Use tf.nn.batch_normalization().
18/01/22 15:01:55 INFO PythonRunner: Times: total = 277977, boot = 2291, init = 11886, finish = 263800
18/01/22 15:01:55 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 2598 bytes result sent to driver
2018-01-22 15:02:26.880517: W tensorflow/core/framework/op_def_util.cc:334] Op BatchNormWithGlobalNormalization is deprecated. It will cease to work in GraphDef version 9. Use tf.nn.batch_normalization().
18/01/22 15:02:31 INFO PythonRunner: Times: total = 313785, boot = 2267, init = 11922, finish = 299596
18/01/22 15:02:31 INFO Executor: Finished task 6.0 in stage 0.0 (TID 6). 1918 bytes result sent to driver
18/01/22 15:04:21 INFO CoarseGrainedExecutorBackend: Driver commanded a shutdown
es result sent to driver
